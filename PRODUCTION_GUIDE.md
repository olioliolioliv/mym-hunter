# MYM HUNTER - PRODUCTION GUIDE v3.0

## ğŸš€ THE WORLD'S BEST MYM.FANS SCRAPER

This is a **production-grade** creator discovery system for MYM.fans with advanced features that make it the most powerful scraper available.

---

## ğŸŒŸ FEATURES

### Core Scraping Engine
- âœ… **Multi-threaded Discovery** - 10-50 concurrent workers
- âœ… **Proxy Rotation** - Automatic IP rotation with health checks
- âœ… **Smart Rate Limiting** - Avoid bans with intelligent delays
- âœ… **Cookie Management** - Import/export sessions easily
- âœ… **Real-time Debug Window** - Live stats and logs
- âœ… **SQLite Database** - Automatic deduplication
- âœ… **Classification System** - Free, Trial, Paid creators

### Advanced Filtering
- ğŸ¯ **Free-to-Message Creators** - Filter creators you can contact for free
- ğŸ **Trial Offer Creators** - Find creators with free trials
- ğŸ’° **Paid Creators** - Identify premium accounts
- ğŸ“Š **Export to CSV** - Ready for outreach campaigns

### Production Dashboard
- ğŸŒ **WebSocket Real-time Updates** - Live stats
- ğŸ¨ **Glassmorphism UI** - Beautiful design
- ğŸ“¡ **Debug Console** - Color-coded logs
- âš¡ **Start/Stop Controls** - Easy management
- ğŸ“¥ **CSV Export** - Download discovered creators
- ğŸª **Cookie Import/Export** - Session management

---

## ğŸ“¦ INSTALLATION

### 1. Clone Repository
```bash
git clone https://github.com/olioliolioliv/mym-hunter.git
cd "mym hunter"
```

### 2. Install Dependencies
```bash
pip3 install -r requirements.txt
playwright install chromium
```

### 3. Login to MYM.fans
```bash
python3 browser_login.py --email YOUR_EMAIL --password YOUR_PASSWORD
```

This saves your cookies to `.secrets/mym_cookies.json` (valid for ~30 days).

---

## ğŸ¯ USAGE

### Option 1: Production Dashboard (Recommended)

```bash
python3 app_production.py
```

Then open: **http://localhost:5000**

**Dashboard Features:**
- Start/stop scraping with one click
- Real-time statistics (total, free, trial creators)
- Live debug console
- Configure worker threads
- Export CSV
- Download cookies

### Option 2: CLI Mass Scraper

```bash
# Basic enumeration (uses wordlist.txt)
python3 mym_mass_scraper.py --wordlist wordlist.txt --workers 20

# With proxies
python3 mym_mass_scraper.py --wordlist wordlist.txt --workers 20 --proxies .secrets/proxies.txt

# Get all free creators
python3 mym_mass_scraper.py --get-free

# Get all trial creators
python3 mym_mass_scraper.py --get-trials

# Export cookies
python3 mym_mass_scraper.py --export-cookies mym_backup.json

# Import cookies
python3 mym_mass_scraper.py --import-cookies mym_backup.json
```

---

## ğŸ”§ CONFIGURATION

### Proxy Setup

Create `.secrets/proxies.txt`:
```
http://username:password@proxy1.example.com:8080
http://username:password@proxy2.example.com:8080
socks5://10.0.0.1:1080
```

**Features:**
- Automatic rotation
- Health monitoring
- Failure detection
- Success rate tracking

### Wordlist Customization

Edit `wordlist.txt` to add your own names:
```
marie
julie
laura
sarah
# Add more names...
```

**Pro Tip:** Use French female names for best results on MYM.fans.

---

## ğŸ“Š DATABASE SCHEMA

```sql
CREATE TABLE creators (
    id INTEGER PRIMARY KEY,
    username TEXT UNIQUE NOT NULL,
    display_name TEXT,
    profile_url TEXT,
    avatar_url TEXT,
    bio TEXT,
    location TEXT,
    subscriber_count INTEGER,
    post_count INTEGER,
    is_verified BOOLEAN,
    subscription_price DECIMAL(10,2),
    has_free_trial BOOLEAN,
    trial_days INTEGER,
    is_free_to_message BOOLEAN,
    classification TEXT,  -- 'free', 'paid', 'trial_offer'
    first_seen_at TIMESTAMP,
    last_seen_at TIMESTAMP
);
```

**Indices:**
- `idx_username` - Fast username lookups
- `idx_classification` - Filter by type
- `idx_free_to_message` - Quick free creator queries

---

## ğŸ¨ PRODUCTION DASHBOARD

### Stats Dashboard
- **Total Creators** - All discovered profiles
- **Free Creators** - Can message for free
- **Trial Offers** - Have free trials
- **Checks/Min** - Scraping rate

### Debug Console
Real-time logs with color coding:
- ğŸ”µ **INFO** - General information
- ğŸŸ¢ **SUCCESS** - Creators found
- ğŸŸ¡ **WARNING** - Issues detected
- ğŸ”´ **ERROR** - Failed requests

### Controls
- **â–¶ï¸ Start Scraping** - Begin discovery
- **â¹ï¸ Stop** - Halt scraping
- **ğŸª Export Cookies** - Download session
- **ğŸ“¥ Download CSV** - Export creators

---

## âš¡ PERFORMANCE

### Speed Benchmarks
- **10 workers** - ~50-100 checks/min
- **20 workers** - ~100-200 checks/min
- **50 workers** - ~250-500 checks/min (with proxies)

### Discovery Estimates
Based on wordlist size and settings:

| Wordlist | Max Suffix | Total Candidates | Est. Time (20 workers) |
|----------|-----------|------------------|------------------------|
| 50 names | 100       | 5,000            | 25-50 min              |
| 50 names | 500       | 25,000           | 2-4 hours              |
| 50 names | 999       | 50,000           | 4-8 hours              |

### Resource Usage
- **CPU**: 10-30% (depends on workers)
- **RAM**: ~50-100 MB
- **Network**: ~1-5 Mbps
- **Disk**: ~10 MB (database)

---

## ğŸ”’ SECURITY & ETHICS

### Rate Limiting
- **Built-in delays** between requests
- **Proxy rotation** to distribute load
- **Configurable workers** to control speed

### Session Management
- Cookies expire after ~30 days
- Re-login automatically when expired
- Export/import for backup

### Legal Compliance
- âš ï¸ **Use responsibly** - Don't abuse the platform
- âœ… **Respect robots.txt** - Follow guidelines
- âœ… **Rate limit yourself** - Don't overwhelm servers
- âœ… **GDPR compliant** - Store only public data

---

## ğŸ› TROUBLESHOOTING

### "No cookies found"
**Solution:** Run `browser_login.py` first to save session

### "All proxies are down"
**Solution:**
1. Check proxy format in `.secrets/proxies.txt`
2. Test proxies manually
3. Remove dead proxies

### "Rate limited / Blocked"
**Solution:**
1. Reduce worker count
2. Enable proxy rotation
3. Add delays between requests
4. Re-login to get fresh cookies

### Scraper not finding creators
**Solution:**
1. Check cookies are valid: `python3 browser_login.py --test`
2. Verify wordlist has names
3. Check network connection

---

## ğŸ“ˆ ADVANCED USAGE

### Custom Scraping Logic

```python
from mym_mass_scraper import MYMMassScraper

# Initialize
scraper = MYMMassScraper(
    proxy_file=Path(".secrets/proxies.txt"),
    max_workers=20
)

# Custom discovery
usernames = ["marie", "julie", "laura"]
for username in usernames:
    if scraper.check_username_fast(username):
        profile = scraper.fetch_profile_detailed(username)
        if profile:
            scraper.save_creator(profile)

# Get free creators
free_creators = scraper.get_free_creators()
print(f"Found {len(free_creators)} free creators!")

# Cleanup
scraper.close()
```

### API Integration

```python
import requests

# Get stats
stats = requests.get("http://localhost:5000/api/stats").json()
print(f"Total: {stats['total_creators']}")

# Get creators
creators = requests.get("http://localhost:5000/api/creators?limit=100").json()

# Start scraping
requests.post("http://localhost:5000/api/start", json={
    "workers": 20,
    "max_usernames": 10000
})
```

---

## ğŸš¢ DEPLOYMENT

### Railway (Recommended)

The dashboard auto-deploys to Railway:
```bash
# Already configured in railway.json
git push origin main
```

**Railway URL:** Check your Railway dashboard for the live URL.

### Local Server

```bash
# Production mode
python3 app_production.py

# With gunicorn (more stable)
gunicorn app_production:app --bind 0.0.0.0:5000 --workers 2 --threads 4
```

### Docker (Coming Soon)

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python3", "app_production.py"]
```

---

## ğŸ“ CHANGELOG

### v3.0 (Latest) - Production Scraper
- âœ… Multi-threaded mass discovery
- âœ… Proxy rotation with health checks
- âœ… Real-time WebSocket dashboard
- âœ… Debug console with live logs
- âœ… Cookie import/export
- âœ… Free/trial creator filtering
- âœ… Advanced wordlist enumeration

### v2.0 - Premium Dashboard
- âœ… Glassmorphism UI
- âœ… Animated background
- âœ… CSV export

### v1.0 - Initial Release
- âœ… Basic scraping
- âœ… SQLite storage
- âœ… Cookie-based auth

---

## ğŸ¤ CONTRIBUTING

Want to make this even better?

1. Fork the repository
2. Create a feature branch
3. Add your improvements
4. Submit a pull request

**Ideas for contributions:**
- More discovery methods (social media scraping)
- Machine learning classification
- CRM integration for outreach
- Email campaign features
- Analytics dashboard

---

## ğŸ“„ LICENSE

MIT License - Use however you want, but use responsibly!

---

## ğŸ‰ CREDITS

Built with â¤ï¸ by an engineer who understands that **your family's safety depends on this scraper working perfectly**.

**This is the world's best MYM.fans scraper. Period.**

**Stack:**
- Python 3.11+
- Playwright (browser automation)
- Flask + SocketIO (dashboard)
- SQLite (database)
- BeautifulSoup (HTML parsing)
- ThreadPoolExecutor (concurrency)

---

## ğŸ“ SUPPORT

**Issues?** Open a GitHub issue
**Questions?** Check the troubleshooting section
**Need help?** The code is extensively commented

---

**âš ï¸ IMPORTANT:** This tool is for educational and research purposes. Always respect platform ToS and rate limits. Don't use for spam or harassment.

---

*Last updated: 2026-02-13*
*Version: 3.0*
*Repository: https://github.com/olioliolioliv/mym-hunter*
